{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "import random #teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'cassandra'\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up fields\n",
    "BODY = Field()\n",
    "NAME = Field()\n",
    "\n",
    "fields = {'name': ('name', NAME), 'body': ('body', BODY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from json\n",
    "train, test = TabularDataset.splits(\n",
    "                path = 'data',\n",
    "                train = f'{PROJECT_NAME}_train.json',\n",
    "                test = f'{PROJECT_NAME}_test.json',\n",
    "                format = 'json',\n",
    "                fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'name': <torchtext.data.field.Field object at 0x7fe2704ce438>, 'body': <torchtext.data.field.Field object at 0x7fe2704ce940>}\n",
      "len(train) 11490\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY.build_vocab(train.body, train.name)\n",
    "NAME.build_vocab(train.body, train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12236\n",
      "12236\n"
     ]
    }
   ],
   "source": [
    "print(len(BODY.vocab))\n",
    "print(len(NAME.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', 94167), (')', 94167), ('.', 67730), (';', 55698), (',', 46923), ('{', 20473), ('}', 20473), ('=', 18020), ('get', 11897), ('<sentence_start>', 11490)]\n"
     ]
    }
   ],
   "source": [
    "print(BODY.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    (train, test), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.name),\n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionFeatures(nn.Module):\n",
    "    \"\"\"\n",
    "    Page 3 of the paper\n",
    "    attention_features (code tokens c, context h_{t-1})\n",
    "     C <- lookupandpad(c, E)\n",
    "     L1 <- ReLU(Conv1d(C, K_{l1}))\n",
    "     L2 <- Conv1d(L1, K_{l2}) * h_{t-1}\n",
    "     Lfeat <- L2/||L2||_2\n",
    "     return Lfeat\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, k1, w1, k2, w2, w3, dropout, prelu):\n",
    "        super(AttentionFeatures, self).__init__()\n",
    "                \n",
    "        self.w1 = w1\n",
    "        self.k1 = k1\n",
    "\n",
    "        self.w2 = w2\n",
    "        self.k2 = k2\n",
    "\n",
    "        #self.w3 = w3 #use this to calculate padding\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, k1, w1)\n",
    "        self.conv2 = nn.Conv1d(k1, k2, w2)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "        self.relu = nn.PReLU() if prelu == True else F.relu\n",
    "\n",
    "    def forward(self, C, h_t):\n",
    "        \n",
    "        #C = embedded body tokens\n",
    "        #h_t = previous hidden state used to predict name token\n",
    "        \n",
    "        #C = [bodies len, batch size, emb dim]\n",
    "        #h_t = [1, batch size, k2]\n",
    "        \n",
    "        C = C.permute(1, 2, 0) #input to conv needs n_channels as dim 1\n",
    "        \n",
    "        #C = [batch size, emb dim, bodies len]\n",
    "        \n",
    "        h_t = h_t.permute(1, 2, 0) #from [1, batch size, k2] to [batch size, k2, 1]\n",
    "        \n",
    "        #h_t = [batch size, k2, 1]\n",
    "        \n",
    "        L_1 = self.do(self.relu(self.conv1(C)))\n",
    "        \n",
    "        #L_1 = [batch size, k1, bodies len - w1 + 1]\n",
    "        \n",
    "        L_2 = self.do(self.conv2(L_1)) * h_t\n",
    "                \n",
    "        #L_2 = [batch size, k2, bodies len - w1 - w2 + 2]\n",
    "        \n",
    "        L_feat = F.normalize(L_2, p=2, dim=1)\n",
    "                \n",
    "        #L_feat = [batch size, k2, bodies len - w1 - w2 + 2]\n",
    "                \n",
    "        return L_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeights(nn.Module):\n",
    "    \"\"\"\n",
    "    Page 3 of the paper\n",
    "    attention_features (attention features Lfeat, kernel K)\n",
    "     return Softmax(Conv1d(Lfeat, K))\n",
    "    \"\"\"\n",
    "    def __init__(self, k2, w3, dropout):\n",
    "        super(AttentionWeights, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(k2, 1, w3)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, L_feat):\n",
    "                \n",
    "        #L_feat = [batch size, k2, bodies len - w1 - w2 + 2]\n",
    "        \n",
    "        x = self.do(self.conv1(L_feat))\n",
    "        \n",
    "        #x = [batch size, 1, bodies len - w1 - w2 - w3 + 3]\n",
    "        \n",
    "        x = x.squeeze(1)\n",
    "        \n",
    "        #x = [batch size, bodies len - w1 - w2 - w3 + 3]\n",
    "        \n",
    "        x = F.softmax(x, dim=1)\n",
    "                \n",
    "        #x = [batch size, bodies len - w1 - w2 - w3 + 3]\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAttentionNetwork(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, k1, k2, w1, w2, w3, dropout, prelu, pad_idx):\n",
    "        super(ConvAttentionNetwork, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.w3 = w3\n",
    "        self.dropout = dropout\n",
    "        self.prelu = prelu\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, k2)\n",
    "        self.attn_feat = AttentionFeatures(embedding_dim, k1, w1, k2, w2, w3, dropout, prelu)\n",
    "        self.attn_weights = AttentionWeights(k2, w3, dropout)\n",
    "        self.bias = nn.Parameter(torch.ones(vocab_size))\n",
    "        \n",
    "        n_padding = w1 + w2 + w3 - 3\n",
    "        self.padding = torch.zeros(n_padding, 1).fill_(pad_idx).long()\n",
    "        \n",
    "    def forward(self, bodies, names, tf=None):\n",
    "        \n",
    "        if tf is None:\n",
    "            tf = self.dropout\n",
    "        \n",
    "        #bodies = [bodies len, batch size]\n",
    "        #names = [names len, batch size]  \n",
    "        \n",
    "        #stores the probabilities generated for each token\n",
    "        outputs = torch.zeros(names.shape[0], names.shape[1], self.vocab_size).to(names.device)\n",
    "        \n",
    "        #outputs = [name len, batch size, vocab dim]\n",
    "        \n",
    "        bodies_padded = torch.cat((bodies, self.padding.expand(-1, bodies.shape[1]).to(bodies.device)))\n",
    "        \n",
    "        #bodies_padded = [bodies len + w1 + w2 + w3 - 3, batch_size]\n",
    "        \n",
    "        emb_b = self.embedding(bodies_padded)\n",
    "        \n",
    "        #emb_b = [bodies len, batch size, emb dim]\n",
    "                \n",
    "        #first input to gru is <sos> token\n",
    "        output = names[0]\n",
    "        #print(output)\n",
    "        #print(output.shape)\n",
    "        #print(self.embedding(output).unsqueeze(0).shape)\n",
    "        #print(\"here\")\n",
    "            \n",
    "        #print(names.shape[0])\n",
    "            \n",
    "        for i in range(1, names.shape[0]):\n",
    "            \n",
    "            #print(names.shape[0])\n",
    "            \n",
    "            #initial hidden state is rnn applied to the <sos> token\n",
    "            _, h_t = self.gru(self.embedding(output).unsqueeze(0))\n",
    "\n",
    "            #h_t = [1, batch size, k2]\n",
    "\n",
    "            L_feat = self.attn_feat(emb_b, h_t)\n",
    "\n",
    "            #L_feat = [batch size, k2, bodies len - w1 - w2 + 2]\n",
    "\n",
    "            alpha = self.attn_weights(L_feat)\n",
    "\n",
    "            #alpha = [batch size, bodies len - w1 - w2 - w3 + 3]\n",
    "\n",
    "            emb_b_slice = emb_b.permute(1, 0, 2)[:, :bodies.shape[0], :]\n",
    "\n",
    "            #emb_b = [batch_size, bodies len, emb dim]\n",
    "\n",
    "            n_hat = torch.sum(alpha.unsqueeze(2) * emb_b_slice, dim=1)\n",
    "\n",
    "            #n_hat = [batch size, emb dim]\n",
    "\n",
    "            E = self.embedding.weight.unsqueeze(0).expand(bodies.shape[1],-1,-1)\n",
    "\n",
    "            #E = [batch size, vocab size, emb dim]\n",
    "\n",
    "            n = torch.bmm(E, n_hat.unsqueeze(2)).squeeze(2) + self.bias.unsqueeze(0).expand(bodies.shape[1], -1)\n",
    "            \n",
    "            #n = [batch size, vocab size]\n",
    "            \n",
    "            #print(n)\n",
    "            #print(n.shape)\n",
    "            #print(n[0])\n",
    "            #print(n[0].shape)\n",
    "            \n",
    "            outputs[i] = n\n",
    "            \n",
    "            #teacher forcing ratio is equal to dropout\n",
    "            if random.random() < self.dropout:\n",
    "                \n",
    "                top1 = n.max(1)[1]\n",
    "                output = top1\n",
    "                \n",
    "            else:\n",
    "                output = names[i]\n",
    "                \n",
    "        #outputs = [name len, batch size, vocab dim]\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(BODY.vocab)\n",
    "EMBEDDING_DIM = 128\n",
    "K1 = 8\n",
    "K2 = 8\n",
    "W1 = 24\n",
    "W2 = 29\n",
    "W3 = 10\n",
    "DROPOUT = 0.25\n",
    "PRELU = True\n",
    "PAD_IDX = BODY.vocab.stoi['<pad>']\n",
    "UNK_IDX = BODY.vocab.stoi['<unk>']\n",
    "\n",
    "model = ConvAttentionNetwork(VOCAB_SIZE, EMBEDDING_DIM, K1, K2, W1, W2, W3, DROPOUT, PRELU, PAD_IDX)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize optimizer, scheduler and loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        bodies = batch.body\n",
    "        names = batch.name\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(bodies, names)\n",
    "        \n",
    "        loss = criterion(output[1:].view(-1, output.shape[2]), names[1:].view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            bodies = batch.body\n",
    "            names = batch.name\n",
    "\n",
    "            output = model(bodies, names, 0) #set teacher forcing to zero\n",
    "\n",
    "            loss = criterion(output[1:].view(-1, output.shape[2]), names[1:].view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/.conda/envs/pytorch04/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 9.284 | Train PPL: 10762.70 | Test Loss: 10.099 | Test PPL: 24311.29 |\n",
      "| Epoch: 02 | Train Loss: 8.547 | Train PPL:  5149.14 | Test Loss: 8.775 | Test PPL:  6469.37 |\n",
      "| Epoch: 03 | Train Loss: 7.875 | Train PPL:  2631.14 | Test Loss: 8.199 | Test PPL:  3637.89 |\n",
      "| Epoch: 04 | Train Loss: 7.438 | Train PPL:  1700.03 | Test Loss: 7.993 | Test PPL:  2960.99 |\n",
      "| Epoch: 05 | Train Loss: 7.046 | Train PPL:  1148.33 | Test Loss: 8.045 | Test PPL:  3118.19 |\n",
      "| Epoch: 06 | Train Loss: 6.755 | Train PPL:   858.76 | Test Loss: 7.311 | Test PPL:  1496.89 |\n",
      "| Epoch: 07 | Train Loss: 6.568 | Train PPL:   712.15 | Test Loss: 6.658 | Test PPL:   779.23 |\n",
      "| Epoch: 08 | Train Loss: 6.356 | Train PPL:   576.22 | Test Loss: 6.235 | Test PPL:   510.33 |\n",
      "| Epoch: 09 | Train Loss: 6.212 | Train PPL:   498.50 | Test Loss: 7.193 | Test PPL:  1330.18 |\n",
      "| Epoch: 10 | Train Loss: 6.014 | Train PPL:   409.08 | Test Loss: 6.566 | Test PPL:   710.33 |\n",
      "| Epoch: 11 | Train Loss: 5.894 | Train PPL:   362.72 | Test Loss: 6.122 | Test PPL:   455.78 |\n",
      "| Epoch: 12 | Train Loss: 5.680 | Train PPL:   293.01 | Test Loss: 5.540 | Test PPL:   254.79 |\n",
      "| Epoch: 13 | Train Loss: 5.573 | Train PPL:   263.32 | Test Loss: 5.490 | Test PPL:   242.31 |\n",
      "| Epoch: 14 | Train Loss: 5.473 | Train PPL:   238.20 | Test Loss: 5.442 | Test PPL:   230.98 |\n",
      "| Epoch: 15 | Train Loss: 5.459 | Train PPL:   234.82 | Test Loss: 5.623 | Test PPL:   276.63 |\n",
      "| Epoch: 16 | Train Loss: 5.176 | Train PPL:   176.90 | Test Loss: 5.052 | Test PPL:   156.36 |\n",
      "| Epoch: 17 | Train Loss: 5.147 | Train PPL:   171.93 | Test Loss: 4.640 | Test PPL:   103.53 |\n",
      "| Epoch: 18 | Train Loss: 5.043 | Train PPL:   154.90 | Test Loss: 4.484 | Test PPL:    88.59 |\n",
      "| Epoch: 19 | Train Loss: 4.913 | Train PPL:   136.05 | Test Loss: 4.284 | Test PPL:    72.50 |\n",
      "| Epoch: 20 | Train Loss: 4.813 | Train PPL:   123.10 | Test Loss: 4.622 | Test PPL:   101.69 |\n",
      "| Epoch: 21 | Train Loss: 4.694 | Train PPL:   109.28 | Test Loss: 4.220 | Test PPL:    68.04 |\n",
      "| Epoch: 22 | Train Loss: 4.657 | Train PPL:   105.35 | Test Loss: 4.226 | Test PPL:    68.41 |\n",
      "| Epoch: 23 | Train Loss: 4.594 | Train PPL:    98.92 | Test Loss: 4.018 | Test PPL:    55.61 |\n",
      "| Epoch: 24 | Train Loss: 4.439 | Train PPL:    84.67 | Test Loss: 3.925 | Test PPL:    50.66 |\n",
      "| Epoch: 25 | Train Loss: 4.400 | Train PPL:    81.49 | Test Loss: 3.822 | Test PPL:    45.68 |\n",
      "| Epoch: 26 | Train Loss: 4.335 | Train PPL:    76.34 | Test Loss: 3.786 | Test PPL:    44.08 |\n",
      "| Epoch: 27 | Train Loss: 4.258 | Train PPL:    70.65 | Test Loss: 3.721 | Test PPL:    41.30 |\n",
      "| Epoch: 28 | Train Loss: 4.189 | Train PPL:    65.94 | Test Loss: 3.743 | Test PPL:    42.23 |\n",
      "| Epoch: 29 | Train Loss: 4.222 | Train PPL:    68.14 | Test Loss: 3.640 | Test PPL:    38.11 |\n",
      "| Epoch: 30 | Train Loss: 4.063 | Train PPL:    58.18 | Test Loss: 3.654 | Test PPL:    38.62 |\n",
      "| Epoch: 31 | Train Loss: 4.017 | Train PPL:    55.54 | Test Loss: 3.456 | Test PPL:    31.67 |\n",
      "| Epoch: 32 | Train Loss: 3.961 | Train PPL:    52.51 | Test Loss: 3.459 | Test PPL:    31.79 |\n",
      "| Epoch: 33 | Train Loss: 3.978 | Train PPL:    53.41 | Test Loss: 3.378 | Test PPL:    29.32 |\n",
      "| Epoch: 34 | Train Loss: 3.867 | Train PPL:    47.80 | Test Loss: 3.397 | Test PPL:    29.86 |\n",
      "| Epoch: 35 | Train Loss: 3.804 | Train PPL:    44.89 | Test Loss: 3.371 | Test PPL:    29.10 |\n",
      "| Epoch: 36 | Train Loss: 3.776 | Train PPL:    43.63 | Test Loss: 3.281 | Test PPL:    26.59 |\n",
      "| Epoch: 37 | Train Loss: 3.712 | Train PPL:    40.92 | Test Loss: 3.271 | Test PPL:    26.33 |\n",
      "| Epoch: 38 | Train Loss: 3.656 | Train PPL:    38.69 | Test Loss: 3.224 | Test PPL:    25.12 |\n",
      "| Epoch: 39 | Train Loss: 3.620 | Train PPL:    37.33 | Test Loss: 3.264 | Test PPL:    26.15 |\n",
      "| Epoch: 40 | Train Loss: 3.586 | Train PPL:    36.08 | Test Loss: 3.225 | Test PPL:    25.16 |\n",
      "| Epoch: 41 | Train Loss: 3.528 | Train PPL:    34.06 | Test Loss: 3.126 | Test PPL:    22.78 |\n",
      "| Epoch: 42 | Train Loss: 3.498 | Train PPL:    33.04 | Test Loss: 3.124 | Test PPL:    22.73 |\n",
      "| Epoch: 43 | Train Loss: 3.450 | Train PPL:    31.49 | Test Loss: 3.091 | Test PPL:    22.00 |\n",
      "| Epoch: 44 | Train Loss: 3.413 | Train PPL:    30.34 | Test Loss: 3.080 | Test PPL:    21.75 |\n",
      "| Epoch: 45 | Train Loss: 3.391 | Train PPL:    29.69 | Test Loss: 3.057 | Test PPL:    21.26 |\n",
      "| Epoch: 46 | Train Loss: 3.359 | Train PPL:    28.75 | Test Loss: 3.070 | Test PPL:    21.54 |\n",
      "| Epoch: 47 | Train Loss: 3.449 | Train PPL:    31.47 | Test Loss: 3.026 | Test PPL:    20.60 |\n",
      "| Epoch: 48 | Train Loss: 3.368 | Train PPL:    29.03 | Test Loss: 3.037 | Test PPL:    20.84 |\n",
      "| Epoch: 49 | Train Loss: 3.266 | Train PPL:    26.20 | Test Loss: 3.055 | Test PPL:    21.23 |\n",
      "| Epoch: 50 | Train Loss: 3.251 | Train PPL:    25.81 | Test Loss: 3.008 | Test PPL:    20.24 |\n",
      "| Epoch: 51 | Train Loss: 3.238 | Train PPL:    25.48 | Test Loss: 2.981 | Test PPL:    19.71 |\n",
      "| Epoch: 52 | Train Loss: 3.208 | Train PPL:    24.74 | Test Loss: 2.969 | Test PPL:    19.48 |\n",
      "| Epoch: 53 | Train Loss: 3.162 | Train PPL:    23.61 | Test Loss: 2.935 | Test PPL:    18.83 |\n",
      "| Epoch: 54 | Train Loss: 3.102 | Train PPL:    22.24 | Test Loss: 2.927 | Test PPL:    18.67 |\n",
      "| Epoch: 55 | Train Loss: 3.103 | Train PPL:    22.27 | Test Loss: 2.909 | Test PPL:    18.33 |\n",
      "| Epoch: 56 | Train Loss: 3.120 | Train PPL:    22.65 | Test Loss: 2.950 | Test PPL:    19.11 |\n",
      "| Epoch: 57 | Train Loss: 3.102 | Train PPL:    22.24 | Test Loss: 2.936 | Test PPL:    18.83 |\n",
      "| Epoch: 58 | Train Loss: 3.085 | Train PPL:    21.87 | Test Loss: 2.926 | Test PPL:    18.66 |\n",
      "| Epoch: 59 | Train Loss: 3.044 | Train PPL:    20.99 | Test Loss: 2.907 | Test PPL:    18.30 |\n",
      "| Epoch: 60 | Train Loss: 3.009 | Train PPL:    20.27 | Test Loss: 2.913 | Test PPL:    18.41 |\n",
      "| Epoch: 61 | Train Loss: 2.984 | Train PPL:    19.76 | Test Loss: 2.869 | Test PPL:    17.61 |\n",
      "| Epoch: 62 | Train Loss: 2.979 | Train PPL:    19.68 | Test Loss: 2.881 | Test PPL:    17.83 |\n",
      "| Epoch: 63 | Train Loss: 2.957 | Train PPL:    19.24 | Test Loss: 2.891 | Test PPL:    18.02 |\n",
      "| Epoch: 64 | Train Loss: 2.937 | Train PPL:    18.86 | Test Loss: 2.870 | Test PPL:    17.63 |\n",
      "| Epoch: 65 | Train Loss: 2.919 | Train PPL:    18.53 | Test Loss: 2.850 | Test PPL:    17.28 |\n",
      "| Epoch: 66 | Train Loss: 2.891 | Train PPL:    18.01 | Test Loss: 2.845 | Test PPL:    17.20 |\n",
      "| Epoch: 67 | Train Loss: 2.882 | Train PPL:    17.84 | Test Loss: 2.875 | Test PPL:    17.73 |\n",
      "| Epoch: 68 | Train Loss: 2.849 | Train PPL:    17.27 | Test Loss: 2.862 | Test PPL:    17.50 |\n",
      "| Epoch: 69 | Train Loss: 2.914 | Train PPL:    18.43 | Test Loss: 2.860 | Test PPL:    17.47 |\n",
      "| Epoch: 70 | Train Loss: 2.834 | Train PPL:    17.01 | Test Loss: 2.833 | Test PPL:    16.99 |\n",
      "| Epoch: 71 | Train Loss: 2.809 | Train PPL:    16.59 | Test Loss: 2.828 | Test PPL:    16.91 |\n",
      "| Epoch: 72 | Train Loss: 2.797 | Train PPL:    16.40 | Test Loss: 2.849 | Test PPL:    17.27 |\n",
      "| Epoch: 73 | Train Loss: 2.763 | Train PPL:    15.84 | Test Loss: 2.882 | Test PPL:    17.84 |\n",
      "| Epoch: 74 | Train Loss: 2.769 | Train PPL:    15.94 | Test Loss: 2.846 | Test PPL:    17.22 |\n",
      "| Epoch: 75 | Train Loss: 2.748 | Train PPL:    15.60 | Test Loss: 2.832 | Test PPL:    16.99 |\n",
      "| Epoch: 76 | Train Loss: 2.712 | Train PPL:    15.06 | Test Loss: 2.835 | Test PPL:    17.02 |\n",
      "| Epoch: 77 | Train Loss: 2.716 | Train PPL:    15.13 | Test Loss: 2.844 | Test PPL:    17.19 |\n",
      "| Epoch: 78 | Train Loss: 2.695 | Train PPL:    14.81 | Test Loss: 2.815 | Test PPL:    16.69 |\n",
      "| Epoch: 79 | Train Loss: 2.683 | Train PPL:    14.63 | Test Loss: 2.833 | Test PPL:    17.00 |\n",
      "| Epoch: 80 | Train Loss: 2.665 | Train PPL:    14.36 | Test Loss: 2.804 | Test PPL:    16.51 |\n",
      "| Epoch: 81 | Train Loss: 2.660 | Train PPL:    14.30 | Test Loss: 2.813 | Test PPL:    16.66 |\n",
      "| Epoch: 82 | Train Loss: 2.639 | Train PPL:    14.00 | Test Loss: 2.808 | Test PPL:    16.58 |\n",
      "| Epoch: 83 | Train Loss: 2.634 | Train PPL:    13.93 | Test Loss: 2.797 | Test PPL:    16.40 |\n",
      "| Epoch: 84 | Train Loss: 2.633 | Train PPL:    13.92 | Test Loss: 2.823 | Test PPL:    16.83 |\n",
      "| Epoch: 85 | Train Loss: 2.630 | Train PPL:    13.87 | Test Loss: 2.808 | Test PPL:    16.58 |\n",
      "| Epoch: 86 | Train Loss: 2.597 | Train PPL:    13.43 | Test Loss: 2.825 | Test PPL:    16.86 |\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "N_EPOCHS = 1000\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir('.save'):\n",
    "    os.makedirs('.save')\n",
    "    \n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    test_loss = evaluate(model, test_iter, criterion)\n",
    "    \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), '.save/model.pt')    \n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):8.2f} | Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):8.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = ConvAttentionNetwork(VOCAB_SIZE, EMBEDDING_DIM, K1, K2, W1, W2, W3, DROPOUT, PRELU, PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('.save/model.pt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(test_iter):\n",
    "    \n",
    "    bodies = batch.body[:,0].unsqueeze(1)\n",
    "    names = batch.name[:,0].unsqueeze(1)\n",
    "    \n",
    "    output = model(bodies, names).squeeze(0)\n",
    "    \n",
    "    bodies = [BODY.vocab.itos[b.item()] for b in bodies.squeeze(1).cpu() if b != PAD_IDX]\n",
    "    names = [NAME.vocab.itos[n.item()] for n in names.squeeze(1).cpu() if n != PAD_IDX][1:-1]\n",
    "    \n",
    "    #print(f'METHOD BODY: {bodies}')\n",
    "    print(f'METHOD NAME: {names}')\n",
    "    \n",
    "    pred = [BODY.vocab.itos[o.max(1)[1].item()] for o in output][1:]\n",
    "    \n",
    "    \n",
    "    print(f'PRED NAME: {pred}')\n",
    "    print('\\n')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_precision_recall(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Get the precision/recall for the given token.\n",
    "    :param predicted_parts: a list of predicted parts\n",
    "    :param gold_set_parts: a list of the golden parts\n",
    "    :return: precision, recall, f1 as floats\n",
    "    \"\"\"\n",
    "    \n",
    "    ground_truth = y_true[:]\n",
    "    \n",
    "    tp = 0\n",
    "    for subtoken in set(y_pred):\n",
    "        if subtoken == UNK_IDX:\n",
    "            continue\n",
    "        if subtoken in ground_truth:\n",
    "            ground_truth.remove(subtoken)\n",
    "            tp += 1\n",
    "\n",
    "    assert tp <= len(y_pred), (tp, len(y_pred))\n",
    "    \n",
    "    if len(y_pred) > 0:\n",
    "        precision = float(tp) / len(y_pred)\n",
    "    else:\n",
    "        precision = 0\n",
    "\n",
    "    assert tp <= len(y_true), (y_true)\n",
    "    \n",
    "    if len(y_true) > 0:\n",
    "        recall = float(tp) / len(y_true)\n",
    "    else:\n",
    "        recall = 0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAttentionNetwork(VOCAB_SIZE, EMBEDDING_DIM, K1, K2, W1, W2, W3, DROPOUT, PRELU, PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('.save/model.pt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1 = 0\n",
    "n_examples = 0\n",
    "\n",
    "for i, batch in enumerate(test_iter):\n",
    "    \n",
    "    bodies = batch.body\n",
    "    names = batch.name\n",
    "    \n",
    "    output = model(bodies, names)\n",
    "\n",
    "    preds = output.max(2)[1]\n",
    "  \n",
    "    examples = names.shape[1]\n",
    "    n_examples += examples\n",
    "    \n",
    "    for ex in range(examples):\n",
    "        actual = [n.item() for n in names[:,ex][1:]]\n",
    "        predicted = [p.item() for p in preds[:,ex][1:]]\n",
    "        _precision, _recall, _f1 = token_precision_recall(predicted, actual)\n",
    "        precision += _precision\n",
    "        recall += _recall\n",
    "        f1 += _f1\n",
    "    \n",
    "print(f1/n_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
